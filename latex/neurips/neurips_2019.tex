\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{A Common Graph Representation for\\Source Code and Developer Documentation}

\author{Breandan Considine\\
breandan.considine@mail.mcgill.ca\\
McGill University}

\begin{document}

\maketitle

\begin{abstract}
Semantic information plays a key role in the code search and synthesis settings. In this work, we propose a graph-based representation for source code and natural language which incorporates semantic and relational features from both domains. We apply this graph to a parsing a corpus of code and developer documents, and demonstrate the effectiveness of a common graph-based representation on three downstream tasks: code search, document recommendation and link prediction.
\end{abstract}

\section{Background and motivation}

In addition to its syntactic structure, source code contains a rich denotational and operational semantics~\citep{henkel2018code}. To effectively reason about code in semantically similar but syntactically diverse settings requires models which incorporate features from the call graph~\citep{gu2016deep} and surrounding typing context~\citep{allamanis2017learning}. Many semantic features, such as data and control flow~\citep{si2018learning} can be represented by a directed acyclic graph (DAG), which admits linear-time solutions to a number of graph problems, including topological sorting, single-source shortest path and reachability queries.

Some programming languages allow users to specify which type of values will inhabit a given variable at runtime. Types allow the compiler to reason about certain properties like nullity~\citep{ekman2007pluggable} and shape~\citep{considine2019kotlingrad}. While types many not appear explicitly in source code, they can often be inferred from the surrounding context using a dataflow graph (DFG). Java, one of the most popular programming languages today, recently introduced local variable type inference~\citet{liddell2019analyzing}, which allows variable types to be omitted, and later inferred by the compiler.

DAGs also have important applications in natural language parsing~\citep{sagae2008shift, quernheim2012dagger}. Various attempts to build semantic representations for natural language have been proposed, notably the pointer network architecture~\citep{vinyals2015pointer, vinyals2015order}. Pointer networks help to capture permutation-invariant semantic relations between natural language entities, and have important applications in dependency parsing~\citep{ma2018stack}, named-entity recognition~\citep{lample2016neural}, and other tasks where sequence representations fall short. \citet{li2017code} extend this work with a copy-mechanism to handle out-of-vocabulary tokens for source code.

Predicting doc-to-doc and code-to-code is a straightforward application of link prediction~\citep{zhang2018link} and code embedding~\citep{gu2018deep} techniques, but cross-domain transfer largely remains unsolved. \citet{robillard2015recommending} first explore the task of predicting reference API documentation, but do not use machine learning. Prior work also associates code comments and source code entities~\citep{panthaplackel2020associating} using machine learning, but only in source code files.

Maintainers of widely-used software projects often publish web-based documentation, typically stored in markup languages like HTML or Markdown. These files contain a collection of natural language sentences, markup, and hyperlinks to other documents. Both the link graph and the document AST contain important semantic information: the markup describes the text in relation to the other entities in the document hierarchy~\citep{yang2016hierarchical}, while the link graph describes the relationship between the parent document and related documents or source code entities. Documents occasionally link to source code, but source code rarely contains links to developer documents.

\section{Proposed approach}

Our research question is as follows: given a single token in either source code or developer documentation and its semantic context, what are the relevant entities in the either source code or documentation?

We would like to infer which documents are relevant to a particular code token, based on the document graph and the surrounding code graph. To infer links between these two domains requires building a multi-relational representation, which incorporates dataflow and control flow aspects. We also need an AST of statically typed computer programs on GitHub. We choose Java, which has a variety of parsing tools for source code~\citep{kovalenko2019pathminer} and natural language~\citep{grella2018non}.

In order to relate the document graph to source code entities, a heuristic is needed. For source code, one such heuristic is the co-occurrence of a salient token. This token can be a code-like fragment or other entity which refers to the selected token.

It is often the case that two documents share a common token. If the token is rare, co-occurrence indicates that two documents likely refer to a common entity. But which is the canonical entity? In order to determine the referent, we need a representation of the surrounding context and the contexts in which the referent occurs.

\section{Data availability and computational requirements}

Our dataset consists of Java projects collected from the Zeal developer docs, and their accompanying source code, collected from GitHub. All projects have a collection of code and documents.

\bibliography{neurips_2019}
\bibliographystyle{plainnat}
\end{document}